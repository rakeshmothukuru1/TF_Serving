{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Below are the important steps in Exporting the Saved Model using Estimator and build_raw_serving_input_receiver_fn:</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifier = tf.estimator.DNNClassifier(feature_columns=my_feature_columns,    \n",
    "###                                        hidden_units=[10, 10],  # Two hidden layers of 10 nodes each.\n",
    "###                                            n_classes=3)\n",
    "\n",
    "### feature_placeholders = {name: tf.placeholder(dtype, [1], name=name + \"_placeholder\") for name, dtype in columns}\n",
    "### serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_placeholders)\n",
    "\n",
    "### Export_Dir = 'Premade_Estimator_Export' #No need of Version Number\n",
    "\n",
    "### Final_Export_Dir = classifier.export_savedmodel(Export_Dir, serving_input_receiver_fn)\n",
    "\n",
    "### Final_Export_Dir = Export_Dir + Folder Created by Current TimeStamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install tensorflow==1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "STEPS = 1000\n",
    "Export_Dir = 'Premade_Estimator_Export_Raw' #No need of Version Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x, train_y), (test_x, test_y) = iris_data.load_data()\n",
    "type(train_x.values[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead of My_Feature_Columns, we use Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below code is taken from https://github.com/travelaudience/tensorflow-export-import-example/blob/master/example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my_feature_columns = []\n",
    "Col_Num = 0\n",
    "for key in zip(train_x.keys()):\n",
    "    Actual_DType = type(train_x.values[0][Col_Num])\n",
    "    my_feature_columns.append((key[0], ))\n",
    "    Col_Num = Col_Num + 1\n",
    "my_feature_columns = [('SepalLength',tf.float64), ('SepalWidth',tf.float64), \n",
    "                      ('PetalLength', tf.float64), ('PetalWidth',tf.float64)]\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_placeholders = {name: tf.placeholder(dtype, [1], name=name + \"_placeholder\")\n",
    "                             for name, dtype in my_feature_columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can convert it to tf.data.Dataset for features in Dict format \n",
    "\n",
    "The make_csv_dataset function returns a tf.data.Dataset of (features, label) pairs, where features is a dictionary: {'feature_name': value}\n",
    "\n",
    "These Dataset objects are iterable. Let's look at a batch of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [('SepalLength', tf.float32), ('SepalWidth', tf.float32),\n",
    "           ('PetalLength', tf.float32), ('PetalWidth', tf.float32)]\n",
    "\n",
    "\n",
    "feature_placeholders = {name: tf.placeholder(dtype, [1], name=name + \"_placeholder\") for name, dtype in columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SepalLength': <tf.Tensor 'SepalLength_placeholder:0' shape=(1,) dtype=float32>, 'SepalWidth': <tf.Tensor 'SepalWidth_placeholder:0' shape=(1,) dtype=float32>, 'PetalLength': <tf.Tensor 'PetalLength_placeholder:0' shape=(1,) dtype=float32>, 'PetalWidth': <tf.Tensor 'PetalWidth_placeholder:0' shape=(1,) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "print(feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 20:15:42.250494 140420877260608 estimator.py:1811] Using temporary folder as model directory: /tmp/tmp0oubsqj9\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers and 10 nodes in each hidden layer.\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=my_feature_columns,    \n",
    "                                        hidden_units=[10, 10],  # Two hidden layers of 10 nodes each.\n",
    "                                            n_classes=3) # The model must choose between 3 classes.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 20:15:42.263200 140420877260608 deprecation.py:323] From /usr/local/google/home/mothukuru/anaconda3/envs/TF_PY_36/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0814 20:15:42.292937 140420877260608 deprecation.py:506] From /usr/local/google/home/mothukuru/anaconda3/envs/TF_PY_36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 20:15:42.944203 140420877260608 deprecation.py:323] From /usr/local/google/home/mothukuru/anaconda3/envs/TF_PY_36/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0814 20:15:43.033409 140420877260608 deprecation.py:506] From /usr/local/google/home/mothukuru/anaconda3/envs/TF_PY_36/lib/python3.6/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 20:15:43.116513 140420877260608 deprecation.py:323] From /usr/local/google/home/mothukuru/anaconda3/envs/TF_PY_36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x7fb5fc772a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(input_fn=lambda:iris_data.train_input_fn(train_x, train_y, BATCH_SIZE),steps=STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 20:15:44.764734 140420877260608 deprecation.py:323] From /usr/local/google/home/mothukuru/anaconda3/envs/TF_PY_36/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 0.967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(input_fn=lambda:iris_data.eval_input_fn(test_x, test_y, BATCH_SIZE))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda:iris_data.eval_input_fn(features = predict_x, labels = None, \n",
    "                                            batch_size=BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction is \"Setosa\" (99.6%), expected \"Setosa\"\n",
      "\n",
      "Prediction is \"Versicolor\" (99.7%), expected \"Versicolor\"\n",
      "\n",
      "Prediction is \"Virginica\" (98.7%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "\n",
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print(template.format(iris_data.SPECIES[class_id],100 * probability, expec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model for Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 20:15:45.422660 140420877260608 deprecation.py:323] From /usr/local/google/home/mothukuru/anaconda3/envs/TF_PY_36/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0814 20:15:45.423661 140420877260608 export_utils.py:182] Export includes no default signature!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to b'Premade_Estimator_Export_Raw/1565793945'\n"
     ]
    }
   ],
   "source": [
    "#feature_spec = tf.feature_column.make_parse_example_spec(my_feature_columns)\n",
    "#serving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
    "serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_placeholders)\n",
    "export_dir = classifier.export_saved_model(Export_Dir, serving_input_receiver_fn)\n",
    "print('Exported to {}'.format(export_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model is stored in /usr/local/google/home/mothukuru/Jupyter_Notebooks/TF_Serving/\n",
    "# Serving_Made_Easy/Serving_Demystified/Premade_Estimator_Export_Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(serving_input_receiver_fn.func_globals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premade_Estimator_Export_Raw/1565788041:\r\n",
      "saved_model.pb\tvariables\r\n",
      "\r\n",
      "Premade_Estimator_Export_Raw/1565788041/variables:\r\n",
      "variables.data-00000-of-00002  variables.data-00001-of-00002  variables.index\r\n"
     ]
    }
   ],
   "source": [
    "!ls -R Premade_Estimator_Export_Raw/1565788041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['predict']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['PetalLength'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1)\r\n",
      "        name: PetalLength_placeholder:0\r\n",
      "    inputs['PetalWidth'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1)\r\n",
      "        name: PetalWidth_placeholder:0\r\n",
      "    inputs['SepalLength'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1)\r\n",
      "        name: SepalLength_placeholder:0\r\n",
      "    inputs['SepalWidth'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1)\r\n",
      "        name: SepalWidth_placeholder:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['all_class_ids'] tensor_info:\r\n",
      "        dtype: DT_INT32\r\n",
      "        shape: (-1, 3)\r\n",
      "        name: dnn/head/predictions/Tile:0\r\n",
      "    outputs['all_classes'] tensor_info:\r\n",
      "        dtype: DT_STRING\r\n",
      "        shape: (-1, 3)\r\n",
      "        name: dnn/head/predictions/Tile_1:0\r\n",
      "    outputs['class_ids'] tensor_info:\r\n",
      "        dtype: DT_INT64\r\n",
      "        shape: (-1, 1)\r\n",
      "        name: dnn/head/predictions/ExpandDims_2:0\r\n",
      "    outputs['classes'] tensor_info:\r\n",
      "        dtype: DT_STRING\r\n",
      "        shape: (-1, 1)\r\n",
      "        name: dnn/head/predictions/str_classes:0\r\n",
      "    outputs['logits'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 3)\r\n",
      "        name: dnn/logits/BiasAdd:0\r\n",
      "    outputs['probabilities'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 3)\r\n",
      "        name: dnn/head/predictions/probabilities:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir Premade_Estimator_Export_Raw/1565788041 --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\r\n",
      "The given SavedModel SignatureDef contains the following output(s):\r\n",
      "Method name is: \r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir Premade_Estimator_Export_Raw/1565788041 \\\n",
    "  --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\r\n",
      "The given SavedModel SignatureDef contains the following output(s):\r\n",
      "Method name is: \r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir Premade_Estimator_Export_Raw/1565788041 \\\n",
    "  --tag_set serve --signature_def classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\r\n",
      "  inputs['PetalLength'] tensor_info:\r\n",
      "      dtype: DT_FLOAT\r\n",
      "      shape: (-1)\r\n",
      "      name: PetalLength_placeholder:0\r\n",
      "  inputs['PetalWidth'] tensor_info:\r\n",
      "      dtype: DT_FLOAT\r\n",
      "      shape: (-1)\r\n",
      "      name: PetalWidth_placeholder:0\r\n",
      "  inputs['SepalLength'] tensor_info:\r\n",
      "      dtype: DT_FLOAT\r\n",
      "      shape: (-1)\r\n",
      "      name: SepalLength_placeholder:0\r\n",
      "  inputs['SepalWidth'] tensor_info:\r\n",
      "      dtype: DT_FLOAT\r\n",
      "      shape: (-1)\r\n",
      "      name: SepalWidth_placeholder:0\r\n",
      "The given SavedModel SignatureDef contains the following output(s):\r\n",
      "  outputs['all_class_ids'] tensor_info:\r\n",
      "      dtype: DT_INT32\r\n",
      "      shape: (-1, 3)\r\n",
      "      name: dnn/head/predictions/Tile:0\r\n",
      "  outputs['all_classes'] tensor_info:\r\n",
      "      dtype: DT_STRING\r\n",
      "      shape: (-1, 3)\r\n",
      "      name: dnn/head/predictions/Tile_1:0\r\n",
      "  outputs['class_ids'] tensor_info:\r\n",
      "      dtype: DT_INT64\r\n",
      "      shape: (-1, 1)\r\n",
      "      name: dnn/head/predictions/ExpandDims_2:0\r\n",
      "  outputs['classes'] tensor_info:\r\n",
      "      dtype: DT_STRING\r\n",
      "      shape: (-1, 1)\r\n",
      "      name: dnn/head/predictions/str_classes:0\r\n",
      "  outputs['logits'] tensor_info:\r\n",
      "      dtype: DT_FLOAT\r\n",
      "      shape: (-1, 3)\r\n",
      "      name: dnn/logits/BiasAdd:0\r\n",
      "  outputs['probabilities'] tensor_info:\r\n",
      "      dtype: DT_FLOAT\r\n",
      "      shape: (-1, 3)\r\n",
      "      name: dnn/head/predictions/probabilities:0\r\n",
      "Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir Premade_Estimator_Export_Raw/1565788041 \\\n",
    "  --tag_set serve --signature_def predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the below commands in Terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo docker pull tensorflow/serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo docker run -p 8501:8501 --mount type=bind,source=/usr/local/google/home/mothukuru/Jupyter_Notebooks/TF_Serving/Serving_Made_Easy/Serving_Demystified/Premade_Estimator_Export_Raw,target=/models/Premade_Estimator_Export_Raw -e MODEL_NAME=Premade_Estimator_Export_Raw -t tensorflow/serving &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working Inference Command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "curl -d '{\"signature_name\":\"predict\",\"instances\": [{\"SepalLength\":[5.1],\"SepalWidth\":[3.3],\"PetalLength\":[1.7],\"PetalWidth\":[0.5]}]}' \\\n",
    "    -X POST http://localhost:8501/v1/models/Premade_Estimator_Export_Raw:predict\n",
    "    \n",
    "**Output:**\n",
    "\n",
    "{\"predictions\": [{\n",
    "            \"all_classes\": [\"0\", \"1\", \"2\"],\n",
    "            \"probabilities\": [0.996251881, 0.00374808488, 3.86118275e-15],\n",
    "            \"logits\": [14.2761269, 8.69337177, -18.9079208],\n",
    "            \"class_ids\": [0],\n",
    "            \"classes\": [\"0\"],\n",
    "            \"all_class_ids\": [0, 1, 2]}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-working Inference Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "curl -d '{\"signature_name\":\"predict\",\"inputs\": [5.1,3.3,1.7,0.5]}' \\\n",
    "    -X POST http://localhost:8501/v1/models/Premade_Estimator_Export_Raw:predict\n",
    "  \n",
    "curl -d '{\"signature_name\":\"predict\",\"instances\": [5.1,3.3,1.7,0.5]}' \\\n",
    "    -X POST http://localhost:8501/v1/models/Premade_Estimator_Export_Raw:predict\n",
    "  \n",
    "curl -d '{\"signature_name\":\"predict\",\"inputs\": [{\"SepalLength\":[5.1],\"SepalWidth\":[3.3],\"PetalLength\":[1.7],\"PetalWidth\":[0.5]}]}' \\\n",
    "    -X POST http://localhost:8501/v1/models/Premade_Estimator_Export_Raw:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below command doesn't work as this Model supports only Predict API and since we have used Raw Serving Input Receiver \n",
    "#### Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "curl -d '{\"examples\":[{\"SepalLength\":[5.1],\"SepalWidth\":[3.3],\"PetalLength\":[1.7],\"PetalWidth\":[0.5]}]}' -X POST http://localhost:8501/v1/models/Premade_Estimator_Export:classify\n",
    "\n",
    "curl -d '{\"signature_name\":\"classify\",\"examples\":[{\"SepalLength\":[5.1],\"SepalWidth\":[3.3],\"PetalLength\":[1.7],\"PetalWidth\":[0.5]}]}' \\ -X POST http://localhost:8501/v1/models/Premade_Estimator_Export:classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go through the below link which comprises KEDB document for different kinds of errors which occured during Inference using REST\n",
    "\n",
    "## https://docs.google.com/spreadsheets/d/1_uZxA2Zp6QD8_46CzXAZXCXVLuiYxybDUGnu72dO58o/edit#gid=1827007920"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rest_simple.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
