{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Saved Model using simple_save\n",
    "\n",
    "## saved_model.simple_save(sess, Export_Dir, inputs={\"X\": X}, outputs={\"y\": Predicted_Output})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run it 4 times in Total => i. Without Version ii. With Version iii. To Show Assertion Error iv. To show picking up the latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Export_Dir = \"IRIS_Data_Export\"\n",
    "#Export_Dir = \"IRIS_Data_Export/2\"\n",
    "#Export_Dir = \"IRIS_Data_Export/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.9, 3. , 5.1, 1.8, 2. ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = genfromtxt('iris_species/Iris_Rakesh.csv', delimiter=',',skip_header =1)\n",
    "\n",
    "my_data[149,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 4  \n",
    "n_hidden1 = 3\n",
    "n_hidden2 = 2\n",
    "n_outputs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "  tf.reset_default_graph()\n",
    "  tf.set_random_seed(seed)\n",
    "  np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32,shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0708 14:22:58.161638 140284249970496 deprecation.py:323] From <ipython-input-9-0667ff3a6d89>:1: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0708 14:22:58.167786 140284249970496 deprecation.py:506] From /usr/local/google/home/mothukuru/anaconda3/envs/TF_PY_36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",activation=tf.nn.relu)\n",
    "hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",activation=tf.nn.relu)\n",
    "logits  = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "Top_2_Logits_Def = tf.math.top_k(input = logits, k=2, sorted=True, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "#saver = tf.train.Saver()\n",
    "\n",
    "arr = np.arange(150)\n",
    "np.random.shuffle(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = my_data.reshape((150,5))\n",
    "my_data = my_data[arr]\n",
    "\n",
    "X_train = my_data[0:120,0:4]\n",
    "X_test = my_data[120:150,0:4]\n",
    "y_train = my_data[0:120,4].astype(\"int32\")\n",
    "y_test = my_data[120:150,4].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = 0\n",
    "def next_batch(X_train,y_train,batch_size):\n",
    "   global cursor\n",
    "   indices = np.arange(cursor,cursor+batch_size)\n",
    "   cursor = cursor + batch_size\n",
    "   return X_train[indices],y_train[indices]\n",
    "\n",
    "\n",
    "from tensorflow import saved_model\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0708 14:22:58.710581 140284249970496 deprecation.py:323] From <ipython-input-15-93a5c554c992>:32: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
      "W0708 14:22:58.710978 140284249970496 deprecation.py:323] From /usr/local/google/home/mothukuru/anaconda3/envs/TF_PY_36/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 Logits =  [[ 0.09631654]\n",
      " [ 0.40740085]\n",
      " [ 0.09631654]\n",
      " [ 0.09631654]\n",
      " [ 0.9071864 ]\n",
      " [-0.07347243]\n",
      " [ 0.09631654]\n",
      " [ 0.09631654]\n",
      " [ 0.94932437]\n",
      " [-0.02403435]\n",
      " [ 0.09631654]\n",
      " [ 0.09631654]\n",
      " [ 0.63364875]\n",
      " [ 0.09631654]\n",
      " [ 0.64696664]\n",
      " [ 0.09631654]\n",
      " [ 0.09631654]\n",
      " [ 0.09631654]\n",
      " [ 0.05898666]\n",
      " [ 0.09631654]\n",
      " [ 0.09631654]\n",
      " [ 0.09631654]\n",
      " [ 0.09631654]\n",
      " [ 0.09631654]\n",
      " [ 0.7093249 ]\n",
      " [ 0.00441615]\n",
      " [ 0.09631654]\n",
      " [ 1.137646  ]\n",
      " [ 0.09631654]\n",
      " [ 0.09631654]]\n",
      "**************************************************************************************************\n",
      "xentropy =  Tensor(\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:0\", shape=(?,), dtype=float32)\n",
      "Predicted_Output =  Tensor(\"y_pred:0\", shape=(), dtype=int32)\n",
      "loss =  Tensor(\"loss:0\", shape=(), dtype=float32)\n",
      "correct =  Tensor(\"in_top_k/InTopKV2:0\", shape=(?,), dtype=bool)\n",
      "accuracy =  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "**************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "   init.run()\n",
    "   for epoch in range(n_epochs):\n",
    "        cursor = 0\n",
    "        for iteration in range(X_train.shape[0] // batch_size):\n",
    "            X_batch, y_batch = next_batch(X_train,y_train,batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch.astype(\"int32\")})\n",
    "            #Predicted_Output = sess.run(logits)\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch.astype(\"int32\")})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test.astype(\"int32\")})\n",
    "        #print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "   #Total_Accuracy = accuracy.eval(feed_dict={X: X_test, y: y_test.astype(\"int32\")})\n",
    "   Predicted_Output = tf.dtypes.cast(np.argmax(logits), dtype = \"int32\", name = 'y_pred')\n",
    "   logits_eval = logits.eval(feed_dict={X: X_test})\n",
    "   Top_2_Logits_Def = tf.math.top_k(input = logits_eval, k=1, sorted=True, name=None)\n",
    "   #Final_Oupput = tf.convert_to_tensor(Top_2_Logits_Def)\n",
    "   Top_2_Logits_Result = sess.run(Top_2_Logits_Def)\n",
    "   print(\"Top 2 Logits = \", Top_2_Logits_Result.values)\n",
    "   print('**************************************************************************************************')\n",
    "   #print('logits = ', logits)\n",
    "   #print('logits.eval = ', logits.eval(feed_dict={X: X_test}))\n",
    "   #print('Sorted logits.eval = ', np.sort(logits.eval(feed_dict={X: X_test}))) \n",
    "   print('xentropy = ', xentropy)\n",
    "   #print('Predicted_Output = ', np.argmax(Predicted_Output))\n",
    "   print('Predicted_Output = ', Predicted_Output)\n",
    "   print('loss = ', loss)\n",
    "   print('correct = ', correct)\n",
    "   print('accuracy = ', accuracy)\n",
    "   print('**************************************************************************************************')\n",
    "   #save_path = saver.save(sess, \"./my_model_final.ckpt\")   \n",
    "   #saved_model.simple_save(sess, Export_Dir, inputs={\"X\": X}, outputs={\"y\": Predicted_Output})\n",
    "   saved_model.simple_save(sess, Export_Dir, inputs={\"X\": X}, outputs={\"y\": Predicted_Output})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance of: Predicted_Output = tf.dtypes.cast(np.argmax(logits), dtype = \"int32\", name = 'y_pred')\n",
    "\n",
    "### For more info, refer https://docs.google.com/document/d/1npeaaGpFsKzvpPW78rRqIXblDewGjPgMQpQVt_T0E3M/edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['X'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 4)\r\n",
      "        name: X:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['y'] tensor_info:\r\n",
      "        dtype: DT_INT32\r\n",
      "        shape: ()\r\n",
      "        name: y_pred:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir IRIS_Data_Export --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo docker pull tensorflow/serving\n",
    "\n",
    "**#Version Number is not required while running our Model using TF Serving. Important to ensure that the Model Name is correct**\n",
    "\n",
    "**Explain about observations from the log**\n",
    "\n",
    "sudo docker run -p 8501:8501 --mount type=bind,source=/home/mothukuru/Serving_Made_Easy/Serving_Demystified/IRIS_Data_Export,target=/models/IRIS_Data_Export -e MODEL_NAME=IRIS_Data_Export -t tensorflow/serving &\n",
    "\n",
    "**Erroneous Inference**\n",
    "\n",
    "curl -d '{\"examples\": [5.1,3.3,1.7,0.5]}' \\\n",
    "  -X POST http://localhost:8501/v1/models/IRIS_Data_Export:predict\n",
    "\n",
    "**Correct Inference and the Rule to remember**\n",
    "\n",
    "curl -d '{\"inputs\": [5.1,3.3,1.7,0.5]}' \\\n",
    "  -X POST http://localhost:8501/v1/models/IRIS_Data_Export:predict\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rest_simple.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
